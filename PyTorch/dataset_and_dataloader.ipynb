{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8616cc3",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1fILm74_ytGv5O06ZZEutD6cyd1mvL-Yj/view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a602e2",
   "metadata": {},
   "source": [
    "## Standalone dataset class and Dataloader method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ba7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1486163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a synthetic classification dataset using sklearn\n",
    "X, y = make_classification(\n",
    "    n_samples=10,       # Number of samples\n",
    "    n_features=2,       # Number of features\n",
    "    n_informative=2,    # Number of informative features\n",
    "    n_redundant=0,      # Number of redundant features\n",
    "    n_classes=2,        # Number of classes\n",
    "    random_state=42     # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e5c4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06833894, -0.97007347],\n",
       "       [-1.14021544, -0.83879234],\n",
       "       [-2.8953973 ,  1.97686236],\n",
       "       [-0.72063436, -0.96059253],\n",
       "       [-1.96287438, -0.99225135],\n",
       "       [-0.9382051 , -0.54304815],\n",
       "       [ 1.72725924, -1.18582677],\n",
       "       [ 1.77736657,  1.51157598],\n",
       "       [ 1.89969252,  0.83444483],\n",
       "       [-0.58723065, -1.97171753]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed20509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04ae67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbd4451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d6f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaaf8c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0683, -0.9701],\n",
       "        [-1.1402, -0.8388],\n",
       "        [-2.8954,  1.9769],\n",
       "        [-0.7206, -0.9606],\n",
       "        [-1.9629, -0.9923],\n",
       "        [-0.9382, -0.5430],\n",
       "        [ 1.7273, -1.1858],\n",
       "        [ 1.7774,  1.5116],\n",
       "        [ 1.8997,  0.8344],\n",
       "        [-0.5872, -1.9717]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99469ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ab4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,features,labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        ## Any data transformation can be done here\n",
    "        ## For example - Lemmatization, NLTK operations\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f037a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "312b1acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95d02929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d90f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7206, -0.9606],\n",
      "        [ 1.8997,  0.8344]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.0683, -0.9701],\n",
      "        [-2.8954,  1.9769]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.1402, -0.8388],\n",
      "        [ 1.7273, -1.1858]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.9382, -0.5430],\n",
      "        [-1.9629, -0.9923]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.5872, -1.9717],\n",
      "        [ 1.7774,  1.5116]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in dataloader:\n",
    "\n",
    "  print(batch_features)\n",
    "  print(batch_labels)\n",
    "  print(\"-\"*50)\n",
    "\n",
    "## In this way, Batches are formed and Mini Batch Gradient Descent can be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8a420",
   "metadata": {},
   "source": [
    "## Integrating with Our previously made training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1faaccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All the imports and pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a48bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))\n",
    "## Till here all previous steps are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b4a6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, features, labels):\n",
    "\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.features)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01c0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e37b85e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-6.2240e-01,  1.3636e+00, -6.0492e-01, -6.1684e-01,  4.5146e-01,\n",
       "         -2.2983e-01, -4.3154e-01, -1.6444e-01,  4.2732e-02,  8.2600e-01,\n",
       "         -5.1895e-01, -3.2657e-02, -4.9724e-01, -4.5499e-01,  4.4539e-01,\n",
       "         -2.6944e-01, -2.8694e-01,  8.7473e-01,  4.4494e-02, -1.1369e-03,\n",
       "         -6.9267e-01,  7.9981e-01, -6.8878e-01, -6.4964e-01, -6.2163e-02,\n",
       "         -4.4776e-01, -5.2598e-01,  8.7933e-02, -4.6812e-01, -4.9429e-02]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "893dea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44e1b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "  def __init__(self, num_features):\n",
    "\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(num_features, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, features):\n",
    "\n",
    "    out = self.linear(features)\n",
    "    out = self.sigmoid(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27b6c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 25\n",
    "\n",
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e15ef9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.07601331919431686\n",
      "Epoch: 2, Loss: 0.17620205879211426\n",
      "Epoch: 3, Loss: 0.10177280753850937\n",
      "Epoch: 4, Loss: 0.13525129854679108\n",
      "Epoch: 5, Loss: 0.03920326754450798\n",
      "Epoch: 6, Loss: 0.2598330080509186\n",
      "Epoch: 7, Loss: 0.28766560554504395\n",
      "Epoch: 8, Loss: 0.05153216794133186\n",
      "Epoch: 9, Loss: 0.1009305790066719\n",
      "Epoch: 10, Loss: 0.10256724059581757\n",
      "Epoch: 11, Loss: 0.022955438122153282\n",
      "Epoch: 12, Loss: 0.12449676543474197\n",
      "Epoch: 13, Loss: 0.06059613823890686\n",
      "Epoch: 14, Loss: 0.010226493701338768\n",
      "Epoch: 15, Loss: 0.03775164112448692\n",
      "Epoch: 16, Loss: 0.03108811378479004\n",
      "Epoch: 17, Loss: 0.09877073019742966\n",
      "Epoch: 18, Loss: 0.06152401119470596\n",
      "Epoch: 19, Loss: 0.014936146326363087\n",
      "Epoch: 20, Loss: 0.04128408804535866\n",
      "Epoch: 21, Loss: 0.8823708295822144\n",
      "Epoch: 22, Loss: 0.017149457708001137\n",
      "Epoch: 23, Loss: 0.1152239441871643\n",
      "Epoch: 24, Loss: 0.007146156392991543\n",
      "Epoch: 25, Loss: 0.0343484990298748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculate\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f24451f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557c3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
