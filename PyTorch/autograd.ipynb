{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca55e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d64e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d40ce63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa22a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fcd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedcee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad \n",
    "## dy/dx is calculated easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d45d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = torch.sin(y)\n",
    "## z = f(y) and y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8978aeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4., requires_grad=True),\n",
       " tensor(16., grad_fn=<PowBackward0>),\n",
       " tensor(-0.2879, grad_fn=<SinBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad79ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.6613)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad\n",
    "## dz/dx is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee012aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NishchaySingla\\AppData\\Local\\Temp\\ipykernel_23452\\4136783279.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  y.grad\n"
     ]
    }
   ],
   "source": [
    "y.grad\n",
    "## Derivative of Intermediate nodes is not calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734811b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now training a basic Perceptron, we need to calculate dL/dw and dL/db\n",
    "import torch\n",
    "\n",
    "# Inputs\n",
    "x = torch.tensor(6.7)  # Input feature\n",
    "y = torch.tensor(0.0)  # True label (binary)\n",
    "\n",
    "w = torch.tensor(1.0,requires_grad=True)  # Weight\n",
    "b = torch.tensor(0.0,requires_grad=True)  # Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01cb3649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1., requires_grad=True), tensor(0., requires_grad=True))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9894a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = w*x + b\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99d37afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.sigmoid(z)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef16af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating loss using y_true and y_pred\n",
    "# Binary Cross-Entropy Loss for scalar\n",
    "def binary_cross_entropy_loss(prediction, target):\n",
    "    epsilon = 1e-8  # To prevent log(0)\n",
    "    prediction = torch.clamp(prediction, epsilon, 1 - epsilon)\n",
    "    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e2aee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = binary_cross_entropy_loss(y_pred,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd7f1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6e0522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.6918), tensor(0.9988))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad,b.grad\n",
    "## In this way dL/dw and dL/db are calculated easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19aa70",
   "metadata": {},
   "source": [
    "### Clearing grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e75e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "282d35c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2., requires_grad=True), tensor(4., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "682ee478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f37fd522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af33b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable gradient tracking\n",
    "# option 1 - requires_grad_(False)\n",
    "# option 2 - detach()\n",
    "# option 3 - torch.no_grad()\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "x,y\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbda810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823e06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
